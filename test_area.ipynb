{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33203fa6-dfb6-47cc-9aa4-8e8828966810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import create_dataloader\n",
    "from general import colorstr, check_img_size\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7ce0dd-6b57-4b53-a0f5-9c21158bc5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858a1113-576d-47d6-bd6a-d5512412292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../coco_kpts/train2017.txt\"  # 118287 images\n",
    "val_path = \"../coco_kpts/val2017.txt\"  # 5000 images\"\n",
    "\n",
    "# number of classes\n",
    "nc = 1\n",
    "\n",
    "names = ['person']\n",
    "\n",
    "gs = 32 # grid size\n",
    "img_size = [640, 640] # [train, test]\n",
    "imgsz, imgsz_test = [check_img_size(x, gs) for x in img_size]\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "hyp_file = \"hyp.yaml\"\n",
    "with open(hyp_file) as f:\n",
    "    hyp = yaml.safe_load(f)  # load hyps\n",
    "\n",
    "cache_images=False\n",
    "rank=-1\n",
    "world_size=1\n",
    "workers=4,\n",
    "image_weights=False \n",
    "quad=False\n",
    "kpt_label = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed651bb0-5372-452d-90f9-25b922db7c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[640, 640]\n"
     ]
    }
   ],
   "source": [
    "img_size.extend([img_size[-1]] * (2 - len(img_size)))\n",
    "print(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb8696c-31d6-44e8-9786-24584c81c912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '..\\coco_kpts\\train2017.cache' images and labels... 56599 found, 0 missing, 0 empty, 0 corrupted: 100%|\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs,\n",
    "                                            hyp=hyp, augment=True, cache=cache_images, rank=rank,\n",
    "                                            world_size=world_size, workers=workers,\n",
    "                                            image_weights=image_weights, quad=quad, prefix=colorstr('train: '), kpt_label=kpt_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce452568-b1ca-4228-beb8-0b3022d6fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class\n",
    "nb = len(dataloader)  # number of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "294941b6-ade2-439d-8939-1c7d75d3d606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 14150\n"
     ]
    }
   ],
   "source": [
    "print(mlc, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50cf42cb-e7db-48ca-9183-53394659e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "gpu = 0\n",
    "# cudnn related setting\n",
    "cudnn.benchmark = cfg.CUDNN.BENCHMARK\n",
    "torch.backends.cudnn.deterministic = cfg.CUDNN.DETERMINISTIC\n",
    "torch.backends.cudnn.enabled = cfg.CUDNN.ENABLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12629b6c-c2c9-41d9-bb8f-9695f4a2eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_config_from_file(cfg, args_file_path):\n",
    "    cfg.defrost()\n",
    "    cfg.merge_from_file(args_file_path)\n",
    "\n",
    "    if not os.path.exists(cfg.DATASET.ROOT):\n",
    "        cfg.DATASET.ROOT = os.path.join(\n",
    "            cfg.DATA_DIR, cfg.DATASET.ROOT\n",
    "        )\n",
    "\n",
    "    cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74bee1b0-1b5b-4029-81c2-d8fb9ef58734",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"experiments/coco/w32/w32_4x_reg03_bs10_512_adam_lr1e-3_coco_x140.yaml\"\n",
    "update_config_from_file(cfg, cfg_path)\n",
    "cfg.defrost()\n",
    "cfg.RANK = 0\n",
    "cfg.freeze()\n",
    "\n",
    "hrnet_model = models.hrnet.get_pose_net(cfg, is_train=True)\n",
    "torch.cuda.set_device(gpu)\n",
    "hrnet_model = hrnet_model.cuda(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb2548ea-1fe2-41b2-a5aa-6d4767427b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class HRNet_Anchor(nn.Module):\n",
    "    \"\"\"\n",
    "    YOLOX model module. The module list is defined by create_yolov3_modules function.\n",
    "    The network returns loss values from three YOLO layers during training\n",
    "    and detection results during test.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, backbone=None, head=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.head = head\n",
    "    \n",
    "    def forward(self, x, targets=None):\n",
    "        # fpn output content features of [dark3, dark4, dark5]\n",
    "        transition_out, merge_out, hrnet_outs = self.backbone(x)\n",
    "        if isinstance(self.head, models.yolo_kpts_head.YOLOXHeadKPTS):\n",
    "            loss, iou_loss, conf_loss, cls_loss, l1_loss, kpts_loss, kpts_vis_loss, num_fg = self.head(\n",
    "                hrnet_outs, targets, x\n",
    "            )\n",
    "            outputs = {\n",
    "                \"total_loss\": loss,\n",
    "                \"iou_loss\": iou_loss,\n",
    "                \"l1_loss\": l1_loss,\n",
    "                \"conf_loss\": conf_loss,\n",
    "                \"cls_loss\": cls_loss,\n",
    "                \"kpts_loss\": kpts_loss,\n",
    "                \"kpts_vis_loss\": kpts_vis_loss,\n",
    "                \"num_fg\": num_fg,\n",
    "            }\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b74f0beb-42a1-4b70-ae1c-7acba66ea3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = models.yolo_kpts_head.YOLOXHeadKPTS(1,in_channels=[32, 64, 128, 256])\n",
    "model = HRNet_Anchor(hrnet_model, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49f54577-c6b3-4fcb-8e44-165c7d3e507b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.HRNet_Anchor"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "749ae017-7a81-4ff4-a10e-3d9a990bb378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchsummary import summary\n",
    "#summary(model, input_size=(3, 512, 512), batch_size=-1, device='cuda')\n",
    "device='cuda'\n",
    "pbar = enumerate(dataloader)\n",
    "nw = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3262d2d2-1d47-45a6-8d3e-80caf0480660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda import amp\n",
    "import torch.optim as optim\n",
    "\n",
    "pg0, pg1, pg2 = [], [], []  # optimizer parameter groups\n",
    "for k, v in model.named_modules():\n",
    "    if hasattr(v, 'bias') and isinstance(v.bias, nn.Parameter):\n",
    "        pg2.append(v.bias)  # biases\n",
    "    if isinstance(v, nn.BatchNorm2d):\n",
    "        pg0.append(v.weight)  # no decay\n",
    "    elif hasattr(v, 'weight') and isinstance(v.weight, nn.Parameter):\n",
    "        pg1.append(v.weight)  # apply decay\n",
    "\n",
    "nbs = 64\n",
    "cuda = True\n",
    "optimizer = optim.Adam(pg0, lr=hyp['lr0'], betas=(hyp['momentum'], 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e7272b0-69ee-46ea-a1a2-5805b6b720bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([17, 40])\n",
      "torch.Size([4, 32, 160, 160])\n",
      "torch.Size([4, 64, 80, 80])\n",
      "torch.Size([4, 128, 40, 40])\n",
      "torch.Size([4, 256, 20, 20])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CCY02\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3487: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "C:\\Users\\CCY02\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3609: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[0.00000e+00, 0.00000e+00, 2.77997e-01, 4.03105e-01, 3.66346e-01, 5.48663e-01, 3.63961e-01, 2.24437e-01, 3.81653e-01, 2.13823e-01, 3.46269e-01, 1.99670e-01, 3.81653e-01, 2.35053e-01, 2.94374e-01, 2.04387e-01, 4.05242e-01, 3.40023e-01, 2.40120e-01, 3.34126e-01, 4.07600e-01, 5.49963e-01, 1.78789e-01, 5.19297e-01,\n",
      "         3.71037e-01, 4.63864e-01, 1.33970e-01, 6.64369e-01, 3.43910e-01, 6.53753e-01, 2.60170e-01, 6.47856e-01, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
      "        [0.00000e+00, 0.00000e+00, 6.04537e-01, 9.20076e-01, 1.78980e-01, 1.59848e-01, 5.34980e-01, 8.93179e-01, 5.44415e-01, 8.82565e-01, 0.00000e+00, 0.00000e+00, 5.66825e-01, 8.73129e-01, 0.00000e+00, 0.00000e+00, 6.22258e-01, 9.22665e-01, 5.30262e-01, 9.41537e-01, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
      "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
      "        [0.00000e+00, 0.00000e+00, 6.77686e-01, 8.85348e-01, 3.37332e-01, 2.29305e-01, 5.75081e-01, 8.95539e-01, 5.88055e-01, 8.77847e-01, 0.00000e+00, 0.00000e+00, 6.29335e-01, 8.51899e-01, 0.00000e+00, 0.00000e+00, 7.17792e-01, 8.73129e-01, 5.92772e-01, 9.09692e-01, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
      "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
      "        [0.00000e+00, 0.00000e+00, 4.57552e-02, 8.46125e-01, 9.15105e-02, 3.07749e-01, 0.00000e+00, 7.72877e-01, 0.00000e+00, 7.51646e-01, 0.00000e+00, 7.68159e-01, 0.00000e+00, 7.42211e-01, 0.00000e+00, 0.00000e+00, 2.07442e-02, 8.15336e-01, 0.00000e+00, 8.80206e-01, 0.00000e+00, 9.62766e-01, 0.00000e+00, 0.00000e+00,\n",
      "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
      "        [1.00000e+00, 0.00000e+00, 9.43022e-01, 4.29489e-02, 9.46441e-02, 8.58978e-02, 9.21749e-01, 2.98137e-03, 9.23190e-01, 9.58058e-05, 9.18867e-01, 1.53861e-03, 0.00000e+00, 0.00000e+00, 9.10223e-01, 4.42417e-03, 9.27512e-01, 1.45236e-02, 9.10223e-01, 1.59664e-02, 9.50564e-01, 2.46231e-02, 9.13104e-01, 2.89514e-02,\n",
      "         9.52005e-01, 1.16381e-02, 9.39038e-01, 1.01953e-02, 0.00000e+00, 0.00000e+00, 9.39038e-01, 4.91503e-02, 0.00000e+00, 0.00000e+00, 9.56327e-01, 4.04936e-02, 0.00000e+00, 0.00000e+00, 9.70735e-01, 6.93492e-02],\n",
      "        [1.00000e+00, 0.00000e+00, 4.15297e-01, 1.82089e-01, 1.13066e-01, 2.73564e-01, 4.04188e-01, 8.49494e-02, 4.08697e-01, 7.93133e-02, 3.95170e-01, 7.93133e-02, 4.19969e-01, 7.93133e-02, 3.86154e-01, 8.04403e-02, 4.31241e-01, 1.12001e-01, 3.83899e-01, 1.16510e-01, 4.57165e-01, 1.68360e-01, 3.71500e-01, 1.78504e-01,\n",
      "         4.30113e-01, 1.68360e-01, 3.71500e-01, 2.16828e-01, 4.35749e-01, 2.29227e-01, 3.89535e-01, 2.30354e-01, 4.31241e-01, 3.07002e-01, 3.99680e-01, 3.08129e-01, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
      "        [1.00000e+00, 0.00000e+00, 3.00714e-01, 1.87336e-01, 1.24282e-01, 2.77656e-01, 3.20777e-01, 8.15679e-02, 3.27540e-01, 7.59319e-02, 3.14015e-01, 7.59319e-02, 3.38812e-01, 8.15679e-02, 3.03870e-01, 7.81864e-02, 3.46703e-01, 1.19891e-01, 2.83581e-01, 1.16510e-01, 3.57974e-01, 1.78504e-01, 2.45257e-01, 1.60470e-01,\n",
      "         3.32049e-01, 1.55961e-01, 2.84709e-01, 1.63851e-01, 3.36558e-01, 2.19082e-01, 2.85835e-01, 2.21337e-01, 3.18524e-01, 3.10383e-01, 2.94853e-01, 3.09256e-01, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
      "        [1.00000e+00, 0.00000e+00, 9.77067e-01, 4.90049e-01, 4.58652e-02, 1.26209e-01, 0.00000e+00, 4.46771e-01, 0.00000e+00, 4.44517e-01, 0.00000e+00, 4.44517e-01, 0.00000e+00, 0.00000e+00, 9.99335e-01, 4.42262e-01, 0.00000e+00, 4.59170e-01, 9.88062e-01, 4.55788e-01, 0.00000e+00, 4.80586e-01, 9.67774e-01, 4.67060e-01,\n",
      "         0.00000e+00, 4.99748e-01, 9.63264e-01, 4.74950e-01, 0.00000e+00, 4.95239e-01, 9.91444e-01, 4.91858e-01, 0.00000e+00, 5.16655e-01, 9.88062e-01, 5.08765e-01, 0.00000e+00, 5.45962e-01, 9.74536e-01, 5.26800e-01],\n",
      "        [1.00000e+00, 0.00000e+00, 4.13966e-01, 4.91503e-01, 1.42733e-01, 1.90616e-01, 4.24477e-01, 4.27609e-01, 4.24477e-01, 4.24227e-01, 4.19969e-01, 4.26482e-01, 0.00000e+00, 0.00000e+00, 4.08697e-01, 4.27609e-01, 4.27859e-01, 4.27609e-01, 4.04188e-01, 4.47898e-01, 4.49275e-01, 4.43389e-01, 4.41385e-01, 4.70441e-01,\n",
      "         4.66183e-01, 4.63678e-01, 4.69564e-01, 4.70441e-01, 4.24477e-01, 4.85095e-01, 4.01934e-01, 4.91858e-01, 4.41385e-01, 5.12147e-01, 3.97426e-01, 5.33563e-01, 4.68437e-01, 5.61742e-01, 3.60229e-01, 5.61742e-01],\n",
      "        [1.00000e+00, 0.00000e+00, 2.56602e-01, 5.44547e-01, 1.50714e-01, 1.16132e-01, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 2.72309e-01, 5.02002e-01, 0.00000e+00, 0.00000e+00, 2.62165e-01, 5.04257e-01, 2.39622e-01, 5.13274e-01, 2.61038e-01, 5.21164e-01, 0.00000e+00, 0.00000e+00, 2.94853e-01, 5.41453e-01,\n",
      "         0.00000e+00, 0.00000e+00, 3.20777e-01, 5.66251e-01, 2.04679e-01, 5.60615e-01, 2.14823e-01, 5.62869e-01, 2.37367e-01, 5.40326e-01, 2.67801e-01, 5.52725e-01, 1.90026e-01, 5.87667e-01, 2.38494e-01, 5.89921e-01],\n",
      "        [1.00000e+00, 0.00000e+00, 1.53815e-01, 5.17405e-01, 1.10429e-01, 1.54952e-01, 2.00170e-01, 4.60297e-01, 0.00000e+00, 0.00000e+00, 1.96789e-01, 4.55788e-01, 0.00000e+00, 0.00000e+00, 1.84390e-01, 4.58043e-01, 1.92280e-01, 4.72696e-01, 1.65228e-01, 4.68187e-01, 1.85517e-01, 4.94112e-01, 1.44939e-01, 4.92985e-01,\n",
      "         1.91153e-01, 5.13274e-01, 1.53956e-01, 5.17783e-01, 1.74245e-01, 5.06511e-01, 1.56211e-01, 5.08765e-01, 1.97916e-01, 5.31309e-01, 1.56211e-01, 5.51598e-01, 1.95662e-01, 5.76396e-01, 1.20142e-01, 5.78650e-01],\n",
      "        [2.00000e+00, 0.00000e+00, 9.79211e-02, 2.21887e-01, 1.95842e-01, 3.47540e-01, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.32329e-02, 9.68903e-02, 4.24551e-02, 1.17345e-01, 0.00000e+00, 1.29034e-01, 3.07663e-02, 1.34878e-01, 0.00000e+00, 8.81236e-02, 9.21329e-02, 1.14424e-01,\n",
      "         0.00000e+00, 6.47451e-02, 1.53499e-01, 8.52010e-02, 0.00000e+00, 2.51767e-01, 0.00000e+00, 2.57611e-01, 0.00000e+00, 2.86834e-01, 4.53774e-02, 2.02090e-01, 0.00000e+00, 3.80345e-01, 4.46632e-03, 2.95601e-01],\n",
      "        [2.00000e+00, 0.00000e+00, 3.37731e-01, 1.82716e-01, 2.76529e-01, 2.84273e-01, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 3.75588e-01, 8.52010e-02, 0.00000e+00, 0.00000e+00, 3.63899e-01, 7.93570e-02, 2.99610e-01, 7.64344e-02, 3.28832e-01, 7.93570e-02, 2.47010e-01, 9.10451e-02, 4.01888e-01, 1.05657e-01,\n",
      "         2.14866e-01, 1.23190e-01, 4.39877e-01, 1.08578e-01, 2.26555e-01, 1.52412e-01, 2.55777e-01, 1.58257e-01, 2.96688e-01, 2.16701e-01, 3.37599e-01, 2.05012e-01, 3.17144e-01, 2.83911e-01, 3.05455e-01, 2.92678e-01],\n",
      "        [2.00000e+00, 0.00000e+00, 9.61261e-01, 9.89928e-01, 7.74774e-02, 2.01436e-02, 0.00000e+00, 9.81682e-01, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 9.81310e-01, 9.81682e-01, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
      "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
      "        [3.00000e+00, 0.00000e+00, 3.46037e-01, 1.75106e-01, 4.29421e-01, 3.50212e-01, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 4.24454e-01, 3.84320e-02, 2.50475e-01, 2.26157e-02, 5.40440e-01, 1.57581e-01, 1.52415e-01, 1.73397e-01,\n",
      "         4.81393e-01, 1.98703e-01, 1.90374e-01, 7.63909e-02, 3.79115e-01, 2.93601e-01, 2.66292e-01, 2.88328e-01, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
      "        [3.00000e+00, 0.00000e+00, 9.73311e-01, 6.31873e-01, 5.33786e-02, 2.77238e-01, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 9.86458e-01, 5.16082e-01, 0.00000e+00, 5.18191e-01, 9.71696e-01, 5.46660e-01, 0.00000e+00, 5.46660e-01, 9.61152e-01, 5.85673e-01, 0.00000e+00, 5.86728e-01,\n",
      "         0.00000e+00, 0.00000e+00, 0.00000e+00, 6.23633e-01, 9.81185e-01, 6.36285e-01, 0.00000e+00, 6.38394e-01, 9.89621e-01, 6.92169e-01, 0.00000e+00, 6.93224e-01, 9.89621e-01, 7.57543e-01, 0.00000e+00, 7.57543e-01],\n",
      "        [3.00000e+00, 0.00000e+00, 4.32304e-01, 6.06841e-01, 2.84302e-01, 3.90545e-01, 4.98263e-01, 4.59144e-01, 5.13025e-01, 4.55981e-01, 4.90883e-01, 4.48600e-01, 5.42549e-01, 4.57035e-01, 0.00000e+00, 0.00000e+00, 5.52038e-01, 5.12919e-01, 4.70848e-01, 5.04484e-01, 5.20406e-01, 5.59313e-01, 4.37107e-01, 5.70912e-01,\n",
      "         5.26733e-01, 4.94994e-01, 4.99317e-01, 5.83565e-01, 5.14080e-01, 6.18360e-01, 4.50814e-01, 6.08871e-01, 5.39385e-01, 6.80571e-01, 3.75951e-01, 7.04823e-01, 4.60304e-01, 7.72305e-01, 3.05305e-01, 7.95502e-01]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b0e007b25762>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#with amp.autocast(enabled=cuda):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-af2412767a82>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, targets)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mtransition_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerge_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhrnet_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolo_kpts_head\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mYOLOXHeadKPTS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             loss, iou_loss, conf_loss, cls_loss, l1_loss, kpts_loss, kpts_vis_loss, num_fg = self.head(\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[0mhrnet_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anchor_HRPose\\models\\yolo_kpts_head.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xin, labels, imgs)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             return self.get_losses(\n\u001b[0m\u001b[0;32m    259\u001b[0m                 \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[0mx_shifts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anchor_HRPose\\models\\yolo_kpts_head.py\u001b[0m in \u001b[0;36mget_losses\u001b[1;34m(self, imgs, x_shifts, y_shifts, expanded_strides, labels, outputs, origin_preds, dtype)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;31m#print(labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;31m# calculate targets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mmixup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmixup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[0mlabel_cut\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 2):  # epoch ------------------------------------------------------------------\n",
    "    model.train()\n",
    "    for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
    "        optimizer.zero_grad()\n",
    "        ni = i + nb * epoch  # number integrated batches (since train start)\n",
    "        imgs = imgs.to(device, non_blocking=True).float() / 255.0  # uint8 to float32, 0-255 to 0.0-1.0\n",
    "        #print(imgs)\n",
    "        #print(targets)\n",
    "\n",
    "         # Forward\n",
    "        print(i)\n",
    "        print(targets.shape)\n",
    "        #with amp.autocast(enabled=cuda):\n",
    "        model = model.to(device)\n",
    "        pred = model(imgs, targets)  # forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a1f351-16be-4ab7-9ecc-fa6c67642cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7576bca-909c-4eca-a2c4-34e93e172f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
