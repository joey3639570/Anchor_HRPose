{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33203fa6-dfb6-47cc-9aa4-8e8828966810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import create_dataloader\n",
    "from general import colorstr, check_img_size\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7ce0dd-6b57-4b53-a0f5-9c21158bc5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858a1113-576d-47d6-bd6a-d5512412292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../coco_kpts/train2017.txt\"  # 118287 images\n",
    "val_path = \"../coco_kpts/val2017.txt\"  # 5000 images\"\n",
    "\n",
    "# number of classes\n",
    "nc = 1\n",
    "\n",
    "names = ['person']\n",
    "\n",
    "gs = 32 # grid size\n",
    "img_size = [640, 640] # [train, test]\n",
    "imgsz, imgsz_test = [check_img_size(x, gs) for x in img_size]\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "hyp_file = \"hyp.yaml\"\n",
    "with open(hyp_file) as f:\n",
    "    hyp = yaml.safe_load(f)  # load hyps\n",
    "\n",
    "cache_images=False\n",
    "rank=-1\n",
    "world_size=1\n",
    "workers=4,\n",
    "image_weights=False \n",
    "quad=False\n",
    "kpt_label = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed651bb0-5372-452d-90f9-25b922db7c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[640, 640]\n"
     ]
    }
   ],
   "source": [
    "img_size.extend([img_size[-1]] * (2 - len(img_size)))\n",
    "print(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb8696c-31d6-44e8-9786-24584c81c912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '..\\coco_kpts\\train2017.cache' images and labels... 56599 found, 0 missing, 0 empty, 0 corrupted: 100%|\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs,\n",
    "                                            hyp=hyp, augment=True, cache=cache_images, rank=rank,\n",
    "                                            world_size=world_size, workers=workers,\n",
    "                                            image_weights=image_weights, quad=quad, prefix=colorstr('train: '), kpt_label=kpt_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce452568-b1ca-4228-beb8-0b3022d6fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class\n",
    "nb = len(dataloader)  # number of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "294941b6-ade2-439d-8939-1c7d75d3d606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 14150\n"
     ]
    }
   ],
   "source": [
    "print(mlc, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d467250-4a7e-45a1-a6c0-858725667c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = enumerate(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e2ebab5-76f7-45c7-aae7-9531ad978227",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-fd711c0a088b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mni\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnb\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mepoch\u001b[0m  \u001b[1;31m# number integrated batches (since train start)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m  \u001b[1;31m# uint8 to float32, 0-255 to 0.0-1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Warmup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
    "    #print(paths)\n",
    "    if i>10:\n",
    "        break\n",
    "    ni = i + nb * epoch  # number integrated batches (since train start)\n",
    "    imgs = imgs.to(device, non_blocking=True).float() / 255.0  # uint8 to float32, 0-255 to 0.0-1.0\n",
    "\n",
    "    # Warmup\n",
    "    if ni <= nw:\n",
    "        xi = [0, nw]  # x interp\n",
    "        # model.gr = np.interp(ni, xi, [0.0, 1.0])  # iou loss ratio (obj_loss = 1.0 or iou)\n",
    "        accumulate = max(1, np.interp(ni, xi, [1, nbs / total_batch_size]).round())\n",
    "        for j, x in enumerate(optimizer.param_groups):\n",
    "            # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n",
    "            x['lr'] = np.interp(ni, xi, [hyp['warmup_bias_lr'] if j == 2 else 0.0, x['initial_lr'] * lf(epoch)])\n",
    "            if 'momentum' in x:\n",
    "                x['momentum'] = np.interp(ni, xi, [hyp['warmup_momentum'], hyp['momentum']])\n",
    "\n",
    "    # Multi-scale\n",
    "    if opt.multi_scale:\n",
    "        sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) // gs * gs  # size\n",
    "        sf = sz / max(imgs.shape[2:])  # scale factor\n",
    "        if sf != 1:\n",
    "            ns = [math.ceil(x * sf / gs) * gs for x in imgs.shape[2:]]  # new shape (stretched to gs-multiple)\n",
    "            imgs = F.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)\n",
    "\n",
    "    # Forward\n",
    "    with amp.autocast(enabled=cuda):\n",
    "        pred = model(imgs)  # forward\n",
    "        loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size\n",
    "        if rank != -1:\n",
    "            loss *= opt.world_size  # gradient averaged between devices in DDP mode\n",
    "        if opt.quad:\n",
    "            loss *= 4.\n",
    "\n",
    "    # Backward\n",
    "    scaler.scale(loss).backward()\n",
    "\n",
    "    # Optimize\n",
    "    if ni % accumulate == 0:\n",
    "        scaler.step(optimizer)  # optimizer.step\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        if ema:\n",
    "            ema.update(model)\n",
    "\n",
    "    # Print\n",
    "    if rank in [-1, 0]:\n",
    "        mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n",
    "        mem = '%.3gG' % (torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n",
    "        s = ('%10s' * 2 + '%10.4g' * 8) % (\n",
    "            '%g/%g' % (epoch, epochs - 1), mem, *mloss, targets.shape[0], imgs.shape[-1])\n",
    "        pbar.set_description(s)\n",
    "\n",
    "        # Plot\n",
    "        if plots and ni < 33:\n",
    "            f = save_dir / f'train_batch{ni}.jpg'  # filename\n",
    "            plot_images(imgs, targets, paths, f, kpt_label=kpt_label)\n",
    "            #Thread(target=plot_images, args=(imgs, targets, paths, f), daemon=True).start()\n",
    "            # if tb_writer:\n",
    "            #     tb_writer.add_image(f, result, dataformats='HWC', global_step=epoch)\n",
    "            #     tb_writer.add_graph(torch.jit.trace(model, imgs, strict=False), [])  # add model graph\n",
    "        elif plots and ni == 10 and wandb_logger.wandb:\n",
    "            wandb_logger.log({\"Mosaics\": [wandb_logger.wandb.Image(str(x), caption=x.name) for x in\n",
    "                                          save_dir.glob('train*.jpg') if x.exists()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf42cb-e7db-48ca-9183-53394659e4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bee1b0-1b5b-4029-81c2-d8fb9ef58734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
